{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Description and dealing with the data\n",
    "This report is about wrangling street map data of Saint Paul in Minnesota, USA.\n",
    "I downloaded the data set from [Minneapolis/Saint Paul](https://mapzen.com/data/metro-extracts/metro/minneapolis-saint-paul_minnesota/).\n",
    "\n",
    "Now I get the data, what I need to do first is to get the probably understand of this data set, I can see the data structure from the wiki [Here](https://wiki.openstreetmap.org/wiki/OSM_XML).\n",
    "\n",
    "There are three main elements in this data set, they are *node*, *way* and *relation*. Also, the detailed description can be seen on this [wiki site](http://wiki.openstreetmap.org/wiki/Elements).\n",
    "\n",
    "With the knowledge of the data, then I should do is to deal with these data in order to get addressable format for MongoDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import the needable packages\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "import codecs\n",
    "import json\n",
    "\n",
    "FILENAME = 'minneapolis-saint-paul_minnesota.osm'\n",
    "\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Rd\": \"Road\",\n",
    "            \"Rd.\": \"Road\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Ave.\": \"Avenue\"\n",
    "            }\n",
    "\n",
    "CREATED = [\"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "\n",
    "#  Get the mininum and maxinum latitude and longitude of this map data for checking the input data's validity.\n",
    "MINLAT = 44.471\n",
    "MINLON = -94.013\n",
    "MAXLAT = 45.415\n",
    "MAXLON = -92.543"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this is a function of judging if a value is float type or not \n",
    "def isfloat(value):\n",
    "    try:\n",
    "        float(value)    \n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this is a function of updating the street name into the same ending.\n",
    "def update_name(name, mapping):\n",
    "    split_name = name.split(' ')\n",
    "    name = \"\"\n",
    "    for word in split_name:\n",
    "        if word in mapping:\n",
    "            name += mapping[word]\n",
    "            break\n",
    "        name += word\n",
    "        name += \" \"\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this is a function of dealing with the node refs which exists only under the 'way' tag\n",
    "def dealing_node_refs(element):\n",
    "    node_refs = []\n",
    "    for nd in element.iter(\"nd\"):\n",
    "        node_refs.append(nd.attrib[\"ref\"])\n",
    "\n",
    "    return node_refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this is a function of dealing with the created information\n",
    "def dealing_created(element):\n",
    "    created = {}\n",
    "    for tag in CREATED:\n",
    "        if tag in element.attrib:\n",
    "            created[tag] = element.attrib[tag]\n",
    "\n",
    "    return created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this is a function of judging if the tag under address is just containing alphabet letters\n",
    "def is_correct_tag(tag_name):\n",
    "    tag_name = tag_name.lower()\n",
    "    if lower.search(tag_name):\n",
    "        return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check the element's location in a right place, if the location is wrong, then I will skip this element.\n",
    "def is_right_location(element):\n",
    "    if \"lat\" in element.attrib and \"lon\" in element.attrib:\n",
    "        lat = element.attrib[\"lat\"]\n",
    "        lon = element.attrib[\"lon\"]\n",
    "        if isfloat(lat) and isfloat(lon):\n",
    "            if MINLAT <= float(lat) <= MAXLAT and MINLON <= float(lon) <= MAXLON:\n",
    "                return True\n",
    "    \n",
    "    return False             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this is a function of dealing with the member information under the relation element\n",
    "def dealing_member(element):\n",
    "    data = []\n",
    "    for mem in element.iter(\"member\"):\n",
    "        member = {}\n",
    "        if \"type\" in mem.attrib:\n",
    "            member[\"type\"] = mem.attrib[\"type\"]\n",
    "        if \"ref\" in mem.attrib:\n",
    "            member[\"ref\"] = mem.attrib[\"ref\"]\n",
    "        if \"role\" in mem.attrib:\n",
    "            member[\"role\"] = mem.attrib[\"role\"]\n",
    "        data.append(member)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_multiple_location(txtfile):\n",
    "    location = []\n",
    "    with open(txtfile, 'r') as f:\n",
    "        for line in f.readline():\n",
    "            pos = line.split(',')\n",
    "            location.append(pos[0]+\"_\"+pos[1])\n",
    "    \n",
    "    return location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_right_postcode(postcode):\n",
    "    if isfloat(postcode):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shape_element(element, multilocations):\n",
    "    node = {}\n",
    "    if element.tag == \"node\" or element.tag == \"way\" or element.tag == \"relation\":  \n",
    "        #make the result smaller, if these is no tag information under a element, I think it's useless\n",
    "        if element.find(\"tag\") is None:\n",
    "            return None \n",
    "        \n",
    "        pos = []    \n",
    "        # if the lat or lon information is absence, then the pos information should not be recorded.\n",
    "        # if the location is multiple, then I skip this element, (or just keep the first element)\n",
    "        if is_right_location(element):\n",
    "            lat = element.attrib[\"lat\"]\n",
    "            lon = element.attrib[\"lon\"]\n",
    "            if (lat + \"_\" + lon) in multilocations:\n",
    "                return None\n",
    "            pos = [float(lat), float(lon)]\n",
    "            node[\"pos\"] = pos\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "        if \"id\" in element.attrib:\n",
    "            node[\"id\"] = element.attrib[\"id\"]\n",
    "          \n",
    "        node[\"tag\"] = element.tag\n",
    "\n",
    "        if \"visible\" in element.attrib:\n",
    "            node[\"visible\"] = element.attrib[\"visible\"]\n",
    "\n",
    "        created = dealing_created(element)\n",
    "        if len(created) > 0:\n",
    "            node[\"created\"] = created        \n",
    " \n",
    "        address = {}\n",
    "        for tag in element.iter(\"tag\"):\n",
    "            if tag.attrib['k'] == \"addr:street\":\n",
    "                address[\"street\"] = update_name(tag.attrib['v'], mapping)\n",
    "            else:\n",
    "                split_k = tag.attrib['k'].split(\":\")\n",
    "                ###let the key in dictionary be lower letter. \n",
    "                ###If there is a second \":\" that separates the type/direction of a street, then the tag will be ignored.\n",
    "                if len(split_k) == 1 and is_correct_tag(split_k[0]):\n",
    "                    if split_k[0].lower() == \"postcode\" and is_right_postcode(tag.attrib['v']):\n",
    "                        node[\"postcode\"] = tag.attrib['v']\n",
    "                    else:\n",
    "                        node[split_k[0].lower()] = tag.attrib['v']\n",
    "                elif len(split_k) == 2 and split_k[0] == 'addr' and is_correct_tag(split_k[1]):\n",
    "                    address[split_k[1].lower()] = tag.attrib['v']\n",
    "\n",
    "        if len(address) > 0:\n",
    "            node[\"address\"] = address\n",
    "\n",
    "        if element.tag == \"way\":\n",
    "            node_refs = dealing_node_refs(element)\n",
    "            if len(node_refs) > 0:\n",
    "                node[\"node_refs\"] = node_refs\n",
    "        \n",
    "        if element.tag == \"relation\":\n",
    "            member = dealing_member(element)\n",
    "            if len(member) > 0:\n",
    "                node[\"member\"] = member\n",
    "          \n",
    "        return node\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_map(file_in, pretty = False):\n",
    "    file_out = \"{0}.json\".format(file_in)\n",
    "    data = []\n",
    "    count = 0\n",
    "    \n",
    "    #read the multiple places, compare every location if it has been in this string, then just skip this element\n",
    "    multilocations = get_multiple_location('multiple-location.txt')\n",
    "    \n",
    "    with codecs.open(file_out, \"w\") as fo:\n",
    "        fo.write(\"[\")\n",
    "        for _, element in ET.iterparse(file_in):\n",
    "            # when I am testing data in my local enviroment, I let the dataset be smaller\n",
    "#             if count > 10000:\n",
    "#                 break\n",
    "            el = shape_element(element, multilocations)\n",
    "            if el:\n",
    "                #data.append(el) the format of json file is very important\n",
    "                if pretty:\n",
    "                    fo.write(json.dumps(el, indent=2)+\"\\n\")\n",
    "                else:\n",
    "                    count += 1\n",
    "                    if count == 1:\n",
    "                        fo.write(json.dumps(el))\n",
    "                    else:\n",
    "                        fo.write(\",\" + \"\\n\" + json.dumps(el))\n",
    "        fo.write(\"]\")\n",
    "    ##return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate the josn format data which can be insert into a mongodb example\n",
    "process_map(FILENAME, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion of Part 1:\n",
    "As the code shows, I have added notes. While several tips I want to add are as follows: \n",
    "\n",
    "1.I find the part 1 and part 2 should be done alternately. When I clean the data by the first time, then I can insert these data into a MongoDB example, I can select some calculated results. Then I will find some problems with my cleaned data, for example, some wrong format postcode, a single location is multiple for several points, then I went back to clean the dataset by second time.\n",
    "\n",
    "2.I notice that there is a tag providing BUS information, if there is more information about which bus stopping, that will be better, because people will know how they can go to this place from other place by bus. While it indeed brings work for data engineers, because they need to calculate the best route from one place to another.\n",
    "\n",
    "If there is more information such as open and close time, it will be more accurate for recommending."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Select interesting result from the dataset\n",
    "In this part, I connected MongoDB locally on my computer first, then I made several pipeline to select interesting results from the dataset. select the number of unique users, select the number of different tags, select the number of different type of building, then sort it with descend order "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient(\"mongodb://localhost:27017\")\n",
    "db = client.examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# insert the data into a collection\n",
    "with open('minneapolis-saint-paul_minnesota.osm.json') as f:\n",
    "    data = json.loads(f.read())\n",
    "    for a in data:\n",
    "        db.saint.insert_one(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def different_postcode():\n",
    "    pipeline = [{\"$match\":{\"address.postcode\":{\"$ne\": None}}},\n",
    "                {\"$group\":{\"_id\":\"$address.postcode\", \"count\":{\"$sum\":1}}}]\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline = different_postcode()\n",
    "result = aggregate(db, pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find some postcode like '55108-1003','MN 55430', while the number of these postcode is small, so what I need to do is to skip these postcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_location_unique():\n",
    "    pipeline = [{\"$group\":{\"_id\":\"$pos\", \"count\":{\"$sum\":1}}},\n",
    "               {\"$match\":{\"count\":{\"$gt\":1}}},\n",
    "               {\"$group\":{\"_id\":None, \"count\":{\"$sum\":1}}}]\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'_id': None, u'count': 49}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = is_location_unique()\n",
    "result = aggregate(db, pipeline)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multiple_user_location():\n",
    "    pipeline = [ {\"$match\":{\"pos\":{\"$ne\":None}}},\n",
    "                {\"$group\":{\"_id\":{\"uid\": \"$created.uid\", \"pos\": \"$pos\"}, \"count\":{\"$sum\":1}}},\n",
    "                {\"$match\":{\"count\":{\"$gt\":1}}},\n",
    "                {\"$group\":{\"_id\":\"$_id.uid\", \"count\":{\"$sum\":\"$count\"}}},\n",
    "                {\"$sort\":{\"count\":-1}},\n",
    "                {\"$limit\": 10}]\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = multiple_user_location()\n",
    "result = aggregate(db, pipeline)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_multiple_location():\n",
    "    pipeline = [{\"$group\":{\"_id\":\"$pos\", \"count\":{\"$sum\":1}}},\n",
    "               {\"$match\":{\"count\":{\"$gt\":1}}},\n",
    "               {\"$project\":{\"pos\":\"$pos\"}}]\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline = find_multiple_location()\n",
    "result = aggregate(db, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "file_out = \"multiple-location.txt\"\n",
    "with codecs.open(file_out, \"w\") as fo:\n",
    "    for pos in result:\n",
    "        if pos['_id']:\n",
    "            fo.write(str(pos['_id'][0]) + \",\" + str(pos['_id'][1]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unique_users():\n",
    "    pipeline = [{\"$match\":{\"created.uid\":{\"$ne\": None}}},\n",
    "                {\"$group\":{\"_id\":\"$created.uid\", \"count\":{\"$sum\":1}}},\n",
    "                {\"$group\":{\"_id\":None, \"count\":{\"$sum\":1}}}]\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "406974"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate the number of element\n",
    "db.saint.find().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def aggregate(db, pipeline):\n",
    "    return [doc for doc in db.saint.aggregate(pipeline)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calculate the number of unique users\n",
    "def users_count():\n",
    "    pipeline = [{\"$match\":{\"created.uid\":{\"$ne\": None}}},\n",
    "                {\"$group\":{\"_id\":\"$created.uid\", \"count\":{\"$sum\":1}}},\n",
    "                {\"$sort\":{\"count\":-1}},\n",
    "                {\"$limit\": 10}]\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = users_count()\n",
    "result = aggregate(db, pipeline)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = unique_users()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = aggregate(db, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate the number of different tags\n",
    "def different_tags():\n",
    "    pipeline = [{\"$group\":{\"_id\":\"$tag\", \"count\":{\"$sum\":1}}}]\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = different_tags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = aggregate(db, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate the number of different type of building, then sort it with descend order\n",
    "def different_highways():\n",
    "    pipeline = [{\"$match\":{\"highway\":{\"$ne\": None}}},\n",
    "                {\"$group\":{\"_id\":\"$highway\", \"count\":{\"$sum\":1}}},\n",
    "                {\"$sort\":{\"count\":-1}}]\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = different_highways()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = aggregate(db, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I want to know which way has the most refence node, then I calculated it and sort it\n",
    "def get_node_refs():\n",
    "    pipeline = [{\"$match\":{\"tag\":{\"$eq\": \"way\"}, \"node_refs\":{\"$ne\": None}}},\n",
    "                {\"$unwind\":\"$node_refs\"},\n",
    "                {\"$group\":{\"_id\":\"$id\", \"count\":{\"$sum\":1}}},\n",
    "                {\"$sort\":{\"count\":-1}},\n",
    "                {\"$limit\": 10}]\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = get_node_refs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = aggregate(db, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#find a certain node from the dataset\n",
    "def search_certain_node(node_id):\n",
    "    pipeline = [{\"$match\":{\"id\":{\"$eq\": node_id}}}]\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline = search_certain_node(\"130711268\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = aggregate(db, pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion of part 2:\n",
    "As the results shown, there are 416975 records after dealing with the data. The reason why there are so less records is that I skipped those records whose tag is None, because I think those records are useless. \n",
    " \n",
    "Among those useful records, I calculated the number of unique uid, 1399, which means there are 1399 users. When I select the numbers of different tags, I find that the way tag is the most, while where still are several ids with None information. From the selection pipeline different_highways, the most building are used for residential, next is for service.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
